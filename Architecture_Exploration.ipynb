{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Fully Connected Network (FCN) example:\n",
    "fcn_model = Sequential()\n",
    "fcn_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "fcn_model.add(Dense(64, activation='relu'))\n",
    "fcn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "fcn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "fcn_model.fit(X_train, y_train, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN example:\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))  # Adjust input_shape as needed\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
    "                    activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='LOG')), \n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=5, executions_per_trial=3, directory='my_dir')\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "def physics_informed_loss(y_true, y_pred):\n",
    "    # This is just a placeholder; you'd need to define how to calculate physics-informed loss\n",
    "    physics_loss = tf.reduce_mean(tf.abs(y_true - y_pred))  # Simple difference (customize as per application)\n",
    "    return physics_loss + tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "# Compile the model with custom loss function\n",
    "model.compile(optimizer='adam', loss=physics_informed_loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = Sequential()\n",
    "hybrid_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "hybrid_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "hybrid_model.add(Flatten())\n",
    "hybrid_model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "hybrid_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "hybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "hybrid_model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Experiment with different activations and visualizations\n",
    "model.add(Dense(128, activation='tanh'))  # Experiment with tanh instead of ReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model (Random Forest, SVM, Gradient Boosting, Neural Networks, etc.), calculate the metrics:\n",
    "\n",
    "# Example: Evaluate Random Forest\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "\n",
    "# Example: Evaluate Deep Learning Model (e.g., CNN)\n",
    "y_pred_dl = model.predict(X_test)\n",
    "accuracy_dl = accuracy_score(y_test, y_pred_dl)\n",
    "precision_dl = precision_score(y_test, y_pred_dl)\n",
    "recall_dl = recall_score(y_test, y_pred_dl)\n",
    "f1_dl = f1_score(y_test, y_pred_dl)\n",
    "rmse_dl = mean_squared_error(y_test, y_pred_dl, squared=False)\n",
    "\n",
    "# Print or log the results for each model:\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}, Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, F1: {f1_rf:.4f}, RMSE: {rmse_rf:.4f}\")\n",
    "print(\"Deep Learning Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_dl:.4f}, Precision: {precision_dl:.4f}, Recall: {recall_dl:.4f}, F1: {f1_dl:.4f}, RMSE: {rmse_dl:.4f}\")\n",
    "\n",
    "# You can also put the results in a DataFrame for comparison:\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Deep Learning'],\n",
    "    'Accuracy': [accuracy_rf, accuracy_dl],\n",
    "    'Precision': [precision_rf, precision_dl],\n",
    "    'Recall': [recall_rf, recall_dl],\n",
    "    'F1 Score': [f1_rf, f1_dl],\n",
    "    'RMSE': [rmse_rf, rmse_dl]\n",
    "})\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a separate validation dataset or an out-of-distribution dataset:\n",
    "X_out_of_distribution, y_out_of_distribution = load_out_of_distribution_data()\n",
    "\n",
    "# Evaluate Random Forest on unseen data:\n",
    "y_pred_ood_rf = rf.predict(X_out_of_distribution)\n",
    "accuracy_ood_rf = accuracy_score(y_out_of_distribution, y_pred_ood_rf)\n",
    "\n",
    "# Evaluate Deep Learning Model on unseen data:\n",
    "y_pred_ood_dl = model.predict(X_out_of_distribution)\n",
    "accuracy_ood_dl = accuracy_score(y_out_of_distribution, y_pred_ood_dl)\n",
    "\n",
    "print(f\"Random Forest Accuracy on Out-of-Distribution Data: {accuracy_ood_rf:.4f}\")\n",
    "print(f\"Deep Learning Model Accuracy on Out-of-Distribution Data: {accuracy_ood_dl:.4f}\")\n",
    "\n",
    "# Overfitting vs. Underfitting Discussion\n",
    "# Overfitting: If the model performs much better on the training set than on the test/out-of-distribution set, it may be overfitting.\n",
    "# Underfitting: If the model performs poorly on both the training and test/out-of-distribution sets, it may be underfitting.\n",
    "\n",
    "# Plot loss/accuracy curves to check for overfitting\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Model Performance Over Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion Matrix for Random Forest\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve for Deep Learning Model\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_dl)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Deep Learning Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Loss vs Epochs plot (for deep learning models)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# If spatial/temporal error maps are needed, visualize errors across geospatial regions or over time (based on dataset)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
