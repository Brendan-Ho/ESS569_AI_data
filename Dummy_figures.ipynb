{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CNN - Filter Activations and Feature Maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filter 1', 'Filter 2', 'Filter 3', 'Filter 4', 'Filter 5']\n"
     ]
    }
   ],
   "source": [
    "# Simulate a protein sequence as a one-hot encoded matrix\n",
    "sequence_length = 50  # Length of the protein sequence\n",
    "num_amino_acids = 20  # Number of possible amino acids (for simplicity, we use 20 for one-hot encoding)\n",
    "protein_sequence = np.random.randint(0, num_amino_acids, sequence_length)\n",
    "\n",
    "# Create a simple feature map (simulated)\n",
    "filters = np.random.randn(5, sequence_length)  # 5 filters for convolution\n",
    "\n",
    "# Apply the filters to the protein sequence (simple dot product for demo)\n",
    "activations = np.dot(filters, protein_sequence).reshape(-1,1)\n",
    "yticklabels=[f'Filter {i+1}' for i in range(activations.shape[0])]\n",
    "print(yticklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot heatmap of activations\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Adjust xticklabels and yticklabels\n",
    "sns.heatmap(activations, cmap=\"YlGnBu\", cbar=True, xticklabels = np.arange(1, 51).reshape(-1, 1), \n",
    "            yticklabels=[f'Filter {i+1}' for i in range(activations.shape[0])])\n",
    "plt.title('CNN Feature Map Activations on Protein Sequence')\n",
    "plt.xlabel('Amino Acid Position')\n",
    "plt.ylabel('Filters')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cnn_feature_map_activations.pdf\")  # Save as PDF\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. ProtBERT - Attention Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Simulate a protein sequence with 20 amino acids\\nprotein_sequence = [\"A\", \"C\", \"G\", \"T\", \"D\", \"V\", \"L\", \"M\", \"E\", \"Q\", \"H\", \"I\", \"K\", \"F\", \"R\", \"P\", \"S\", \"W\", \"Y\", \"N\"]\\nnum_amino_acids = len(protein_sequence)\\n\\n# Simulate attention scores between each pair of amino acids\\nattention_matrix = np.random.rand(num_amino_acids, num_amino_acids)\\n\\n# Create a heatmap for the attention map\\nfig = px.imshow(attention_matrix, labels=dict(x=\"Amino Acid\", y=\"Amino Acid\", color=\"Attention Weight\"), \\n                x=protein_sequence, y=protein_sequence, color_continuous_scale=\"Viridis\")\\nfig.update_layout(title=\"ProtBERT Attention Map for Protein Sequence\")\\nfig.write_image(\"protbert_attention_map.pdf\")  # Save as PDF\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Simulate a protein sequence with 20 amino acids\n",
    "protein_sequence = [\"A\", \"C\", \"G\", \"T\", \"D\", \"V\", \"L\", \"M\", \"E\", \"Q\", \"H\", \"I\", \"K\", \"F\", \"R\", \"P\", \"S\", \"W\", \"Y\", \"N\"]\n",
    "num_amino_acids = len(protein_sequence)\n",
    "\n",
    "# Simulate attention scores between each pair of amino acids\n",
    "attention_matrix = np.random.rand(num_amino_acids, num_amino_acids)\n",
    "\n",
    "# Create a heatmap for the attention map\n",
    "fig = px.imshow(attention_matrix, labels=dict(x=\"Amino Acid\", y=\"Amino Acid\", color=\"Attention Weight\"), \n",
    "                x=protein_sequence, y=protein_sequence, color_continuous_scale=\"Viridis\")\n",
    "fig.update_layout(title=\"ProtBERT Attention Map for Protein Sequence\")\n",
    "fig.write_image(\"protbert_attention_map.pdf\")  # Save as PDF\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. LSTM - Hidden State Evolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating hidden state values for each time step of a protein sequence\n",
    "sequence_length = 50\n",
    "hidden_state = np.random.randn(sequence_length, 3)  # 3 hidden state dimensions\n",
    "\n",
    "# Plot the evolution of the hidden state\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hidden_state[:, 0], label='Hidden State 1', color='r')\n",
    "plt.plot(hidden_state[:, 1], label='Hidden State 2', color='g')\n",
    "plt.plot(hidden_state[:, 2], label='Hidden State 3', color='b')\n",
    "plt.title('LSTM Hidden State Evolution')\n",
    "plt.xlabel('Time Step (Amino Acid Position)')\n",
    "plt.ylabel('Hidden State Value')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lstm_hidden_state_evolution.pdf\")  # Save as PDF\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. LSTM - Cell State Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating cell state values for each time step of a protein sequence\n",
    "sequence_length = 50\n",
    "cell_state = np.random.randn(sequence_length)\n",
    "\n",
    "# Plot the evolution of the cell state\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cell_state, label='Cell State', color='orange')\n",
    "plt.title('LSTM Cell State Evolution')\n",
    "plt.xlabel('Time Step (Amino Acid Position)')\n",
    "plt.ylabel('Cell State Value')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lstm_cell_state_evolution.pdf\")  # Save as PDF\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Comparison of CNN, ProtBERT, and LSTM Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for the model comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Drawing boxes for each model's architecture\n",
    "cnn_box = mpatches.FancyBboxPatch((0.05, 0.6), 0.3, 0.3, boxstyle=\"round,pad=0.1\", edgecolor=\"black\", facecolor=\"lightblue\")\n",
    "protbert_box = mpatches.FancyBboxPatch((0.4, 0.6), 0.3, 0.3, boxstyle=\"round,pad=0.1\", edgecolor=\"black\", facecolor=\"lightgreen\")\n",
    "lstm_box = mpatches.FancyBboxPatch((0.75, 0.6), 0.3, 0.3, boxstyle=\"round,pad=0.1\", edgecolor=\"black\", facecolor=\"lightcoral\")\n",
    "\n",
    "# Add the boxes to the plot\n",
    "ax.add_patch(cnn_box)\n",
    "ax.add_patch(protbert_box)\n",
    "ax.add_patch(lstm_box)\n",
    "\n",
    "# Add text inside the boxes\n",
    "ax.text(0.2, 0.8, 'CNN: Convolutional Layers + Pooling', fontsize=12, ha='center')\n",
    "ax.text(0.55, 0.8, 'ProtBERT: Transformer with Attention', fontsize=12, ha='center')\n",
    "ax.text(0.9, 0.8, 'LSTM: Recurrent Layers with Memory', fontsize=12, ha='center')\n",
    "\n",
    "# Add arrows to show data flow between boxes\n",
    "ax.arrow(0.35, 0.75, 0.05, 0, head_width=0.02, head_length=0.03, fc='black', ec='black')\n",
    "ax.arrow(0.7, 0.75, 0.05, 0, head_width=0.02, head_length=0.03, fc='black', ec='black')\n",
    "\n",
    "# Title and Labels\n",
    "ax.set_title(\"Comparison of CNN, ProtBERT, and LSTM Architectures for Protein Sequences\")\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_comparison.pdf\")  # Save as PDF\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Performance Comparison (Bar Chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated performance metrics\n",
    "models = ['CNN', 'ProtBERT', 'LSTM']\n",
    "accuracy = [0.85, 0.90, 0.88]\n",
    "precision = [0.80, 0.85, 0.83]\n",
    "recall = [0.82, 0.87, 0.84]\n",
    "\n",
    "# Plotting the performance comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.2\n",
    "x = np.arange(len(models))\n",
    "\n",
    "# Creating bars for each metric\n",
    "ax.bar(x - bar_width, accuracy, bar_width, label='Accuracy')\n",
    "ax.bar(x, precision, bar_width, label='Precision')\n",
    "ax.bar(x + bar_width, recall, bar_width, label='Recall')\n",
    "\n",
    "# Labeling the plot\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Performance Comparison: CNN, ProtBERT, and LSTM')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"performance_comparison.pdf\")  # Save as PDF\n",
    "plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
