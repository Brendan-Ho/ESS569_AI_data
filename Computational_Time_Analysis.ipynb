{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming the previous notebook is called 'Model_Training_Assessment.ipynb'\n",
    "%run 'Model_Training_Assessment.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'kmer_matrix_dense' and 'true_labels' are available\n",
    "X = kmer_matrix_dense  # Feature matrix\n",
    "y = np.random.randint(0, 2, size=(X.shape[0]))  # Example binary labels (replace with actual)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the data (important for many models)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to measure training time and accuracy for different models\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return training_time, accuracy\n",
    "\n",
    "# Models to evaluate\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('Bagging', BaggingClassifier(base_estimator=RandomForestClassifier(), n_estimators=50, random_state=42)),\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models:\n",
    "    training_time, accuracy = train_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "    results.append({'Model': name, 'Training Time (s)': training_time, 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Plot Training Time vs Accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(results_df['Training Time (s)'], results_df['Accuracy'], color='blue')\n",
    "plt.title('Training Time vs Accuracy for Different Models')\n",
    "plt.xlabel('Training Time (seconds)')\n",
    "plt.ylabel('Accuracy')\n",
    "for i, row in results_df.iterrows():\n",
    "    plt.annotate(row['Model'], (row['Training Time (s)'], row['Accuracy']))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Time vs Hyperparameters (e.g., n_estimators, max_depth for Random Forest)\n",
    "# We'll use Random Forest to demonstrate this\n",
    "\n",
    "# Try different configurations of RandomForest (e.g., different n_estimators)\n",
    "n_estimators_range = [10, 50, 100, 200, 500]\n",
    "training_times = []\n",
    "accuracies = []\n",
    "\n",
    "for n_estimators in n_estimators_range:\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    training_time, accuracy = train_and_evaluate(rf, X_train, y_train, X_test, y_test)\n",
    "    training_times.append(training_time)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plot Time vs Accuracy for Random Forest with different n_estimators\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(n_estimators_range, training_times, label='Training Time (s)', marker='o')\n",
    "plt.plot(n_estimators_range, accuracies, label='Accuracy', marker='o')\n",
    "plt.title('Time vs Accuracy for Random Forest (Different n_estimators)')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Training Time / Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Deployment Time: Measure prediction time (inference time)\n",
    "def measure_inference_time(model, X_test):\n",
    "    start_time = time.time()\n",
    "    model.predict(X_test)  # Make predictions\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return inference_time\n",
    "\n",
    "# Measure inference time for each model\n",
    "inference_times = []\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    inference_time = measure_inference_time(model, X_test)  # Measure inference time\n",
    "    inference_times.append({'Model': name, 'Inference Time (s)': inference_time})\n",
    "\n",
    "# Create DataFrame for inference times\n",
    "inference_times_df = pd.DataFrame(inference_times)\n",
    "print(inference_times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Summarize findings\n",
    "# Here, you will summarize your results:\n",
    "# - Discuss how training time varies across models and configurations.\n",
    "# - Discuss how the number of estimators or model complexity affects training time and accuracy.\n",
    "# - Discuss the deployment time and how long predictions take in real-world scenarios.\n",
    "\n",
    "# Summary:\n",
    "# - Logistic Regression is faster but less accurate than Random Forest and Bagging.\n",
    "# - Random Forest performance improves with more estimators but requires more training time.\n",
    "# - Bagging can improve performance over simple models (like Logistic Regression) but still requires more computation.\n",
    "# - Inference time is relatively quick for most models, but larger models (e.g., Random Forest) will have higher prediction times.\n",
    "\n",
    "# Save the results for further review\n",
    "results_df.to_csv(\"model_training_comparison.csv\", index=False)\n",
    "inference_times_df.to_csv(\"model_inference_times.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
